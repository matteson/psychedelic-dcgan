{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import os\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(image, resize_height=64, resize_width=64):\n",
    "    if resize_height or resize_width:\n",
    "        resizedImage = scipy.misc.imresize(image, [resize_height, resize_width])\n",
    "    else:\n",
    "        resizedImage = image\n",
    "    return np.array(resizedImage)/127.5 - 1.\n",
    "\n",
    "def get_image(image_path, resize_height=64, resize_width=64):\n",
    "    image = scipy.misc.imread(image_path).astype(np.float)\n",
    "    return transform(image, resize_height, resize_width)\n",
    "\n",
    "def get_images(image_paths, resize_height=64, resize_width=64):\n",
    "    return [get_image(p, resize_height, resize_width) for p in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageFileNames = glob.glob(\"/home/ubuntu/data/images_full/*.png\")\n",
    "\n",
    "fullImages = get_images(imageFileNames, resize_height=256, resize_width=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_images = len(fullImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCrops(batchSize, cropHeight=64, cropWidth=64):\n",
    "    # image is height x width x channels\n",
    "    imageHeight, imageWidth, channels = fullImages[0].shape\n",
    "    \n",
    "    imageY = np.floor(\n",
    "            np.multiply(\n",
    "                np.random.rand(batchSize),(imageHeight - cropHeight)\n",
    "            )\n",
    "        ).astype('int')\n",
    "    imageX = np.floor(\n",
    "            np.multiply(\n",
    "                np.random.rand(batchSize),(imageWidth - cropWidth)\n",
    "            )\n",
    "    ).astype('int')\n",
    "    \n",
    "    select = np.floor(np.random.rand(batch_size)*num_images).astype('int')\n",
    "    \n",
    "    return [fullImages[r][y:(y+cropHeight), x:(x+cropWidth),:] for (x, y, r) in zip(imageX, imageY, select)]\n",
    "\n",
    "def getEmbeds(batchSize, embedLength):\n",
    "    return np.random.rand(batchSize, embedLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showarray(a, transform='tanh', fmt='jpeg'):\n",
    "    if transform == 'tanh':\n",
    "        a = np.uint8(((a+1)/2)*255)\n",
    "    else:\n",
    "        a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildMinibatchDiscriminator(features, numFeatures, kernels, kernelDim=5, reuse=False):\n",
    "    with tf.variable_scope(\"minibatch\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        # TODO: no undefined dimensions until 1.0 release\n",
    "        batchTensor = tf.get_variable('disc_minibatch',\n",
    "                       shape=[numFeatures, kernels, kernelDim],\n",
    "                       initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                       regularizer=slim.l2_regularizer(0.05))\n",
    "        \n",
    "        flatFeatures = tf.reshape(features, (16,-1))\n",
    "        multFeatures = tf.einsum('ij,jkl->ikl',flatFeatures, batchTensor)\n",
    "        multFeaturesExpanded1 = tf.expand_dims(multFeatures,[1])\n",
    "\n",
    "        fn = lambda x: x - multFeatures\n",
    "\n",
    "        multFeaturesDiff = tf.exp(\n",
    "            -tf.reduce_sum(\n",
    "                tf.abs(\n",
    "                    tf.map_fn(fn, multFeaturesExpanded1)\n",
    "                ),\n",
    "            axis=[3])\n",
    "        )\n",
    "\n",
    "        output = tf.reduce_sum(multFeaturesDiff, axis=[1]) - 1\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Network building\n",
    "def buildBatchL1(layer):\n",
    "    layerMean = tf.reduce_mean(layer, axis=[0])\n",
    "    layerBatchL1 = tf.reduce_mean(tf.abs(layer - layerMean))\n",
    "    \n",
    "    return layerBatchL1\n",
    "\n",
    "def buildDiscriminator(images, kernel_size=[3,3], reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        # Convolutional discriminator\n",
    "        discConv1 = slim.conv2d(images, 64, kernel_size,  stride=1, activation_fn=tf.nn.elu, scope='disc_conv_1_1')\n",
    "        \n",
    "        discPool1 = slim.max_pool2d(discConv1, [2, 2], scope='disc_pool_1')\n",
    "                \n",
    "        discConv4 = slim.conv2d(discPool1, 96, kernel_size,  stride=1, activation_fn=tf.nn.elu, scope='disc_conv_4')\n",
    "        \n",
    "        discPool2 = slim.max_pool2d(discConv4, [2, 2], scope='disc_pool_2')\n",
    "        \n",
    "        discConv7 = slim.conv2d(discPool2, 96, kernel_size,  stride=1, activation_fn=tf.nn.elu, scope='disc_conv_7')\n",
    "        \n",
    "        discPool3 = slim.max_pool2d(discConv7, [2, 2], scope='disc_pool_3')\n",
    "        \n",
    "        discConv10 = slim.conv2d(discPool3, 64, kernel_size,  stride=1, activation_fn=tf.nn.elu, scope='disc_conv_10')\n",
    "        \n",
    "        discPool4 = slim.max_pool2d(discConv10, [2, 2], scope='disc_pool_4')\n",
    "        \n",
    "        numFeatures = height/16*width/16*64\n",
    "        miniBatchDisc = buildMinibatchDiscriminator(discPool4, numFeatures, kernels=100, reuse=reuse)\n",
    "        \n",
    "        miniBatchSummary = slim.fully_connected(miniBatchDisc, 1, activation_fn = None, scope='disc_full_mini')\n",
    "        \n",
    "        convBottleNeck = tf.reshape(discPool4, (16, 1024))\n",
    "        convSummary = slim.fully_connected(convBottleNeck, 1, activation_fn = None, scope='disc_full_conv')\n",
    "\n",
    "        discriminatorBottleneck = tf.concat([convSummary, miniBatchSummary], 1)\n",
    "        \n",
    "        discriminator_logits = slim.fully_connected(discriminatorBottleneck, 1, activation_fn = None, scope='disc_full_final')\n",
    "        discriminator = tf.nn.sigmoid(discriminator_logits)\n",
    "        \n",
    "        discriminatorLayers = [\n",
    "            discriminator,\n",
    "            discriminator_logits,\n",
    "            discriminatorBottleneck,\n",
    "            convSummary,\n",
    "            convBottleNeck,\n",
    "            miniBatchSummary,\n",
    "            miniBatchDisc,\n",
    "            discPool4,\n",
    "            discConv10,\n",
    "            discPool3,\n",
    "            discConv7,\n",
    "            discPool2,\n",
    "            discConv4,\n",
    "            discPool1,\n",
    "            discConv1,\n",
    "        ]\n",
    "    return discriminatorLayers\n",
    "\n",
    "def buildGenerator(embeddings, kernel_size=[3,3], reuse=False):\n",
    "    with tf.variable_scope(\"generator\") as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        # Reshape embeddings       \n",
    "        generatorLinear = slim.fully_connected(embeddings, finalConvFilterLayers, activation_fn = None, scope='gen_linear')\n",
    "        generatorReshape = tf.reshape(generatorLinear, [-1, finalHeight, finalWidth, dim*8])\n",
    "        \n",
    "        generatorConv1_1 = slim.conv2d(generatorReshape, 64, kernel_size,  \n",
    "                                               stride=1, activation_fn=tf.nn.elu, normalizer_fn=slim.batch_norm, scope='gen_conv_1_1')\n",
    "        \n",
    "        generatorResize1 = tf.image.resize_images(generatorConv1_1, size=(finalHeight*2, finalWidth*2), method=1 )\n",
    "        generatorConv2_1 = slim.conv2d(generatorResize1, 64, kernel_size,  \n",
    "                                               stride=1, activation_fn=tf.nn.elu, scope='gen_conv_2_1')\n",
    "        generatorConv2_2 = slim.conv2d(generatorConv2_1, 32, kernel_size,  \n",
    "                                               stride=1, activation_fn=tf.nn.elu, scope='gen_conv_2_2')\n",
    "        \n",
    "        generatorResize2 = tf.image.resize_images(generatorConv2_2, size=(finalHeight*4, finalWidth*4), method=1 )\n",
    "        generatorConv3_1 = slim.conv2d(generatorResize2, 32, kernel_size,  \n",
    "                                               stride=1, activation_fn=tf.nn.elu, scope='gen_conv_3_1')\n",
    "        generatorConv3_2 = slim.conv2d(generatorConv3_1, 16, kernel_size,  \n",
    "                                               stride=1, activation_fn=tf.nn.elu, scope='gen_conv_3_2')\n",
    "        \n",
    "        generatorResize3 = tf.image.resize_images(generatorConv3_2, size=(finalHeight*8, finalWidth*8), method=1 )\n",
    "        generatorConv4_1 = slim.conv2d(generatorResize3, 8, kernel_size,  stride=1,\n",
    "                                          activation_fn=None, scope='gen_conv_4_1')\n",
    "        \n",
    "        generatorResize4 = tf.image.resize_images(generatorConv4_1, size=(finalHeight*16, finalWidth*16), method=1 )\n",
    "        generatorConv5_1 = slim.conv2d(generatorResize4, channels, kernel_size,  stride=1,\n",
    "                                          activation_fn=None, scope='gen_conv_5_1')\n",
    "\n",
    "        generatorOut = tf.tanh(generatorConv5_1)\n",
    "        \n",
    "        generatorLayers = [\n",
    "            generatorOut,\n",
    "            generatorConv5_1,\n",
    "            generatorResize4,\n",
    "            generatorConv4_1,\n",
    "            generatorResize3,\n",
    "            generatorConv3_2,\n",
    "            generatorConv3_1,\n",
    "            generatorResize2,\n",
    "            generatorConv2_2,\n",
    "            generatorConv2_1,\n",
    "            generatorResize1,\n",
    "            generatorConv1_1,\n",
    "            generatorReshape,\n",
    "            generatorLinear,\n",
    "        ]\n",
    "        \n",
    "        return generatorLayers\n",
    "        \n",
    "def buildModel(images, embeddings):\n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                      weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "\n",
    "        discRealLayers  = buildDiscriminator(images, reuse=False)\n",
    "        generatorLayers = buildGenerator(embeddings, reuse=False)\n",
    "        discFakeLayers  = buildDiscriminator(generatorLayers[0], reuse=True)\n",
    "\n",
    "    return  discRealLayers, discFakeLayers, generatorLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "\n",
    "dim = 16;\n",
    "\n",
    "finalWidth = np.int_(width/16)\n",
    "finalHeight = np.int(height/16)\n",
    "finalConvFilterLayers = np.int(finalHeight*finalWidth*(dim*8))\n",
    "\n",
    "imageDims = [height, width, channels]\n",
    "embedDims = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.InteractiveSession(graph=graph)\n",
    "\n",
    "images     = tf.placeholder(tf.float32, [None] + [None, None, 3], name='images')\n",
    "embeddings = tf.placeholder(tf.float32, [None] + embedDims, name='embeddings')\n",
    "\n",
    "tf.add_to_collection(\"images\", images)\n",
    "tf.add_to_collection(\"embeddings\", embeddings)\n",
    "\n",
    "discRealLayers, discFakeLayers, generatorLayers = buildModel(images, embeddings)\n",
    "discRealLogits = discRealLayers[1]\n",
    "discFakeLogits = discFakeLayers[1]\n",
    "generator = generatorLayers[0]\n",
    "\n",
    "fakeMiniBatchDisc = discFakeLayers[2]\n",
    "realMiniBatchDisc = discRealLayers[2]\n",
    "\n",
    "# discriminator and generator losses\n",
    "discLossesReal = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=discRealLogits, labels=tf.ones_like(discRealLogits))\n",
    "discRealTotal = tf.reduce_mean(discLossesReal)\n",
    "\n",
    "discLossesFake = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=discFakeLogits, labels=tf.zeros_like(discFakeLogits))\n",
    "discFakeTotal = tf.reduce_mean(discLossesFake)\n",
    "\n",
    "genLoss = tf.reduce_mean(\n",
    "  tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=discFakeLogits, labels=tf.ones_like(discFakeLogits)))\n",
    "\n",
    "discLoss = discRealTotal + discFakeTotal\n",
    "\n",
    "# need to optimize disc and gen only with respect to their parameters\n",
    "variables = tf.trainable_variables()\n",
    "discVars = [var for var in variables if 'disc_' in var.name]\n",
    "genVars  = [var for var in variables if 'gen_' in var.name]\n",
    "\n",
    "beta1 = 0.5\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "# create training ops on loss\n",
    "dOptim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1) \\\n",
    "          .minimize(discLoss, var_list=discVars)\n",
    "\n",
    "gOptim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1) \\\n",
    "          .minimize(genLoss, var_list=genVars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jter:  145500 , Discriminator loss:  0.0 , \n",
      " Generator loss:  2858.81 , \n",
      " Minibatch Fake:  [ -851.37017822 -1923.15429688] , \n",
      " Minibatch Real:  [ -9.10306885e+02   3.78825963e-01]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6601254855fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedDims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             sess.run(gOptim,\n\u001b[0;32m---> 22\u001b[0;31m                 feed_dict={embeddings: x_embed, learning_rate: gdLearnRate})\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mprintIter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "numEpochs = 1\n",
    "numBatchPerEpoch = 1000000\n",
    "printIter = 25\n",
    "l1LossWeight = 1\n",
    "gdLearnRate = .001\n",
    "\n",
    "for iter in range(numEpochs):\n",
    "    \n",
    "    for jter in range(numBatchPerEpoch):\n",
    "\n",
    "        # update discriminator and generator\n",
    "        for kter in range(1):\n",
    "            x_embed = np.random.rand(16, embedDims[0])\n",
    "            x_image = getCrops(16, cropHeight=height, cropWidth=width)\n",
    "            sess.run([gOptim, dOptim],\n",
    "                feed_dict={images: x_image, embeddings: x_embed, learning_rate: gdLearnRate})\n",
    "        \n",
    "        for kter in range(4):\n",
    "            # update generator 2x because discriminator sees more examples (fake + real)\n",
    "            x_embed = np.random.rand(16, embedDims[0])\n",
    "            sess.run(gOptim,\n",
    "                feed_dict={embeddings: x_embed, learning_rate: gdLearnRate})\n",
    "    \n",
    "        if jter%printIter == 0: \n",
    "            x_image = getCrops(16, cropHeight=height, cropWidth=width)\n",
    "            x_embed = np.random.rand(16, embedDims[0])\n",
    "            currentDiscLoss, currentReal, currentFake, currentGenLoss, currentFakeMini, currentRealMini = sess.run(\n",
    "                [discLoss, discLossesReal, discLossesFake, genLoss, fakeMiniBatchDisc, realMiniBatchDisc], \n",
    "                feed_dict={images: x_image, embeddings: x_embed})\n",
    "            clear_output()\n",
    "            print(\n",
    "                'jter: ', jter, ',',\n",
    "                'Discriminator loss: ', currentDiscLoss, ',', '\\n',\n",
    "                'Generator loss: ', currentGenLoss, ',', '\\n',\n",
    "                'Minibatch Fake: ', np.mean(currentFakeMini,0) , ',','\\n',\n",
    "                'Minibatch Real: ', np.mean(currentRealMini,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_embed = np.random.rand(16, embedDims[0])\n",
    "# x_embed = 0.5*np.ones((1, embedDims[0]))\n",
    "# x_embed[0,20000:30000] = 1\n",
    "\n",
    "samples, layerSamples = sess.run((generator, generatorLayers[-3]), feed_dict={embeddings: x_embed})\n",
    "#samples = getCrops(16, cropHeight=height, cropWidth=width)\n",
    "\n",
    "for sample in samples:\n",
    "    showarray(sample)\n",
    "\n",
    "print(np.max(layerSamples, axis=(1,2,3)))\n",
    "print(layerSamples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Freeze model\n",
    "checkpoint_prefix = \"./\"\n",
    "checkpoint_state_name = \"my-model\"\n",
    "input_graph_name = \"my-model.pb\"\n",
    "output_graph_name = \"frozen-model.pb\"\n",
    "input_graph_path = os.path.join(\"./\", \"my-model.pb\")\n",
    "input_saver_def_path = \"\"\n",
    "input_binary = False\n",
    "output_node_names = 'discriminator/disc_conv_4/convolution'\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_graph_path = os.path.join(\"./\", output_graph_name)\n",
    "clear_devices = False\n",
    "\n",
    "# We save out the graph to disk, and then call the const conversion\n",
    "# routine.\n",
    "tf.train.write_graph(sess.graph_def, \"./\", \"my-model.pb\", True) #proto\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "checkpoint_path = saver.save(sess,\"./my-model.data\")\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph_path, input_saver_def_path,\n",
    "                          input_binary, checkpoint_path, output_node_names,\n",
    "                          restore_op_name, filename_tensor_name,\n",
    "                          output_graph_path, clear_devices, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.01302782e-06]\n",
      " [  1.74654076e-06]\n",
      " [  2.75998580e-04]\n",
      " [  1.82114109e-05]\n",
      " [  6.19580896e-06]\n",
      " [  3.02006247e-05]\n",
      " [  3.20706546e-04]\n",
      " [  3.06647067e-04]\n",
      " [  1.45609709e-04]\n",
      " [  8.61895842e-06]\n",
      " [  1.71568336e-05]\n",
      " [  3.46408633e-05]\n",
      " [  1.05657164e-04]\n",
      " [  3.70653179e-05]\n",
      " [  8.27882650e-06]\n",
      " [  1.43511907e-05]] 8.33187e-05\n",
      "[[  1.94667721e+00]\n",
      " [  1.43256426e+00]\n",
      " [  4.02907637e-04]\n",
      " [  8.35512340e-01]\n",
      " [  2.10230276e-01]\n",
      " [  1.07395481e-05]\n",
      " [  1.75760388e+00]\n",
      " [  4.50042295e+00]\n",
      " [  2.36718846e-03]\n",
      " [  2.88805403e-02]\n",
      " [  3.72046083e-02]\n",
      " [  1.22876399e-05]\n",
      " [  1.83857039e-01]\n",
      " [  1.79373637e-06]\n",
      " [  1.41834879e+00]\n",
      " [  3.22605586e+00]] 0.97376\n"
     ]
    }
   ],
   "source": [
    "scores = sess.run(discLossesReal, feed_dict={images: x_image})\n",
    "print(scores, np.mean(scores))\n",
    "scores = sess.run(discLossesFake, feed_dict={embeddings: x_embed})\n",
    "print(scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\ni+eERSxjCknDvwOR271nFOMbJXCpCEnzX5bvXz/4Pmf/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showarray(x_image[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
